## Blog Post Assignment 3: Choosing Regression Variables
*This blog post will discuss choosing variables for a regression model*  

I have a strong interest in the topic of regression and model building, so I personally enjoy thinking about variables for a model and trying to choose what's best! However, I haven't built many models beyond the classroom, with few exceptions coming at work. It's safe to say there is a lot to consider.

Generally, I try to think about the question I'm trying to answer with the model I have. I also logically think about my response variable and things that are related to the variable. After all, if I'm the one building a model or trying to answer a question, I should have an idea on how to answer it! For example, if my response variable is strikeouts in a season for a pitcher I immediatley begin to consider pitcher handedness, fastball velocity, number of total pitches the pitcher is able to throw, and innings they've pitched. All four of those will be related to the number of strikeouts a pitcher gets in a season. Although they're related to strikeouts, this doesn't guarantee they're significant. However, at least some variables that are related to the response should return some significance or lead us in the direction of significant variables.

I am personally not a huge fan of stepwise, forward, or backward selection due to it's simplicity. Despite this, I will sometimes fit a model with several variables and see which return significance (low p-value from F-test). This isn't necessarily a sound technique either, and also quite simple, but can be a quick way to decide which variables to keep in a model. Rather, criteron-based procedures, like the ones mentioned in the attached [document](https://www.biostat.jhsph.edu/~iruczins/teaching/jf/ch10.pdf), are what I typically adhere by. Comparing multiple models with different variable combinations using the criteron can help us pick the right variables. Specifically, I like to use Adjusted R-Squared or Root Mean Square Error (RMSE) to compare. Penalized based procedures like Adjusted R-Squared make more sense to be because the model doesn't "improve" simply due to adding a variable.

I like to use EDA as another tool to help us choose variables for our model. Correlation plots, scatterplots, and more can visualize potential relationships and patterns between variables and the response that can lead us to significant variable choices for our model. Furthermore, I have an interest in employing other techniques that include things like data mining, as mentioned in Bruce Ratner's [paper](https://link.springer.com/content/pdf/10.1057/jt.2009.26.pdf) on page 69. I like to think I already use some of the techniques listed in *The Natural Seven-step Cycle of Statistical Modeling and Analysis* on page 71 of Ratner's paper, but am looking forward to trying something like this in full capacity in the future.

Overall, there are several ways to go about choosing variables for a model. Preferred techniques vary among data scientists. The three articles listed for the homework assignment each make great points on model selection and offer insight on several techniques.

